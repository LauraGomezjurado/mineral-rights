#!/usr/bin/env python3
"""
Simulate the complete mineral rights classification pipeline
"""

import argparse
import json
import time
from pathlib import Path
from typing import Dict, Any, List
from utils import load_prompts, extract_sample_text, detect_key_phrases

def simulate_ocr_extraction(pdf_path: str) -> Dict[str, Any]:
    """Simulate OCR extraction with multiple tools"""
    print("üîç Step 1: OCR Text Extraction")
    print("   ‚Ä¢ Running TrOCR (printed)...")
    print("   ‚Ä¢ Running TrOCR (handwritten)...")
    print("   ‚Ä¢ Running Donut...")
    print("   ‚Ä¢ Running Tesseract...")
    
    # Simulate processing time
    time.sleep(2)
    
    # Extract actual sample text for demonstration
    sample_text = extract_sample_text(pdf_path)
    
    ocr_results = {
        "trocr_printed": {
            "text": sample_text,
            "confidence": 0.92,
            "processing_time": 3.2
        },
        "trocr_handwritten": {
            "text": sample_text,
            "confidence": 0.87,
            "processing_time": 3.8
        },
        "donut": {
            "text": sample_text,
            "confidence": 0.89,
            "processing_time": 2.1
        },
        "tesseract": {
            "text": sample_text,
            "confidence": 0.76,
            "processing_time": 1.5
        }
    }
    
    # Select best OCR result
    best_ocr = max(ocr_results.items(), key=lambda x: x[1]["confidence"])
    
    print(f"   ‚úÖ Best OCR: {best_ocr[0]} (confidence: {best_ocr[1]['confidence']:.2f})")
    
    return {
        "all_results": ocr_results,
        "best_result": {
            "tool": best_ocr[0],
            "text": best_ocr[1]["text"],
            "confidence": best_ocr[1]["confidence"]
        }
    }

def simulate_text_normalization(text: str) -> Dict[str, Any]:
    """Simulate text cleaning and normalization"""
    print("\nüßπ Step 2: Text Normalization")
    print("   ‚Ä¢ Removing OCR artifacts...")
    print("   ‚Ä¢ Standardizing legal terminology...")
    print("   ‚Ä¢ Fixing common OCR errors...")
    
    time.sleep(1)
    
    # Simulate normalization improvements
    normalized_text = text.replace("  ", " ").strip()
    
    improvements = [
        "Fixed 3 spacing issues",
        "Corrected 2 legal term spellings",
        "Removed 1 OCR artifact"
    ]
    
    print(f"   ‚úÖ Normalization complete: {', '.join(improvements)}")
    
    return {
        "original_text": text,
        "normalized_text": normalized_text,
        "improvements": improvements
    }

def simulate_phrase_detection(text: str) -> Dict[str, Any]:
    """Simulate key phrase detection"""
    print("\nüîç Step 3: Key Phrase Detection")
    print("   ‚Ä¢ Scanning for reservation phrases...")
    print("   ‚Ä¢ Analyzing legal language patterns...")
    
    time.sleep(1)
    
    # Detect actual phrases in the text
    detected_phrases = detect_key_phrases(text)
    
    print(f"   ‚úÖ Found {len(detected_phrases)} key phrases")
    for phrase in detected_phrases:
        print(f"      ‚Ä¢ '{phrase['phrase']}' (confidence: {phrase['confidence']:.2f})")
    
    return {
        "detected_phrases": detected_phrases,
        "has_reservations": len(detected_phrases) > 0
    }

def simulate_classification(text: str, phrases: List[Dict]) -> Dict[str, Any]:
    """Simulate LLM-based classification"""
    print("\nü§ñ Step 4: LLM Classification")
    print("   ‚Ä¢ Loading classification prompt...")
    print("   ‚Ä¢ Analyzing document context...")
    print("   ‚Ä¢ Generating classification reasoning...")
    
    time.sleep(2)
    
    # Load classification prompt
    prompts = load_prompts()
    
    # Simulate classification logic
    has_reservation_phrases = len(phrases) > 0
    
    if has_reservation_phrases:
        classification = "WITH_RESERVATIONS"
        confidence = 0.91
        reasoning = f"Document contains {len(phrases)} clear reservation phrases indicating mineral rights are reserved by the grantor."
    else:
        classification = "WITHOUT_RESERVATIONS"
        confidence = 0.88
        reasoning = "No explicit mineral rights reservation language found in the document."
    
    print(f"   ‚úÖ Classification: {classification} (confidence: {confidence:.2f})")
    
    return {
        "classification": classification,
        "confidence": confidence,
        "reasoning": reasoning,
        "prompt_used": prompts["classify"][:100] + "..."
    }

def simulate_verification(classification_result: Dict[str, Any], text: str) -> Dict[str, Any]:
    """Simulate self-verification step"""
    print("\n‚úÖ Step 5: Self-Verification")
    print("   ‚Ä¢ Double-checking classification...")
    print("   ‚Ä¢ Analyzing potential edge cases...")
    print("   ‚Ä¢ Calculating final confidence...")
    
    time.sleep(1)
    
    # Load verification prompt
    prompts = load_prompts()
    
    # Simulate verification logic
    original_confidence = classification_result["confidence"]
    
    # Simulate verification adjustments
    if original_confidence > 0.9:
        final_confidence = original_confidence
        verification_notes = "High confidence classification confirmed"
    else:
        final_confidence = max(0.7, original_confidence - 0.05)
        verification_notes = "Moderate confidence - recommend human review"
    
    print(f"   ‚úÖ Verification complete: {final_confidence:.2f} confidence")
    
    return {
        "original_confidence": original_confidence,
        "final_confidence": final_confidence,
        "verification_notes": verification_notes,
        "verified_classification": classification_result["classification"]
    }

def run_pipeline_simulation(pdf_path: str, output_path: str = None):
    """Run complete pipeline simulation"""
    print("üöÄ Starting Mineral Rights Classification Pipeline")
    print(f"üìÑ Processing: {Path(pdf_path).name}")
    print("=" * 60)
    
    start_time = time.time()
    
    # Step 1: OCR Extraction
    ocr_result = simulate_ocr_extraction(pdf_path)
    
    # Step 2: Text Normalization
    norm_result = simulate_text_normalization(ocr_result["best_result"]["text"])
    
    # Step 3: Phrase Detection
    phrase_result = simulate_phrase_detection(norm_result["normalized_text"])
    
    # Step 4: Classification
    class_result = simulate_classification(
        norm_result["normalized_text"], 
        phrase_result["detected_phrases"]
    )
    
    # Step 5: Verification
    verify_result = simulate_verification(class_result, norm_result["normalized_text"])
    
    # Compile final results
    total_time = time.time() - start_time
    
    final_result = {
        "input_file": str(pdf_path),
        "processing_time": total_time,
        "pipeline_steps": {
            "ocr_extraction": ocr_result,
            "text_normalization": norm_result,
            "phrase_detection": phrase_result,
            "classification": class_result,
            "verification": verify_result
        },
        "final_output": {
            "classification": verify_result["verified_classification"],
            "confidence": verify_result["final_confidence"],
            "key_phrases_found": len(phrase_result["detected_phrases"]),
            "reasoning": class_result["reasoning"]
        }
    }
    
    print("\n" + "=" * 60)
    print("üéØ FINAL CLASSIFICATION RESULT")
    print("=" * 60)
    print(f"üìã Document: {Path(pdf_path).name}")
    print(f"üè∑Ô∏è  Classification: {final_result['final_output']['classification']}")
    print(f"üìä Confidence: {final_result['final_output']['confidence']:.2f}")
    print(f"üîç Key Phrases: {final_result['final_output']['key_phrases_found']}")
    print(f"üí≠ Reasoning: {final_result['final_output']['reasoning']}")
    print(f"‚è±Ô∏è  Total Time: {total_time:.1f}s")
    
    # Save results if output path provided
    if output_path:
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Results saved to: {output_file}")
    
    return final_result

def main():
    parser = argparse.ArgumentParser(description='Simulate mineral rights classification pipeline')
    parser.add_argument('--input', type=str, required=True,
                       help='Input PDF file path')
    parser.add_argument('--output', type=str,
                       help='Output JSON file path (optional)')
    
    args = parser.parse_args()
    
    # Validate input
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"‚ùå Error: Input file {input_path} does not exist")
        return
    
    # Set default output path
    output_path = args.output
    if not output_path:
        output_path = f"data/outputs/{input_path.stem}_classification.json"
    
    # Run simulation
    try:
        run_pipeline_simulation(str(input_path), output_path)
    except Exception as e:
        print(f"‚ùå Pipeline simulation failed: {e}")

if __name__ == "__main__":
    main() 